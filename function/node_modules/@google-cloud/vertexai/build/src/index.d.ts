/**
 * @license
 * Copyright 2023 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
import { GoogleAuth, GoogleAuthOptions } from 'google-auth-library';
import { Content, CountTokensRequest, CountTokensResponse, GenerateContentRequest, GenerateContentResult, GenerationConfig, ModelParams, Part, SafetySetting, StreamGenerateContentResult, VertexInit } from './types/content';
export * from './types';
/**
 * Base class for authenticating to Vertex, creates the preview namespace.
 */
export declare class VertexAI {
    preview: VertexAI_Preview;
    /**
     * @constructor
     * @param {VertexInit} init - assign authentication related information,
     *     including project and location string, to instantiate a Vertex AI
     * client.
     */
    constructor(init: VertexInit);
}
/**
 * VertexAI class internal implementation for authentication.
 */
export declare class VertexAI_Preview {
    readonly project: string;
    readonly location: string;
    readonly apiEndpoint?: string | undefined;
    readonly googleAuthOptions?: GoogleAuthOptions<import("google-auth-library/build/src/auth/googleauth").JSONClient> | undefined;
    protected googleAuth: GoogleAuth;
    /**
     * @constructor
     * @param {string} - project The Google Cloud project to use for the request
     * @param {string} - location The Google Cloud project location to use for the request
     * @param {string} - [apiEndpoint] The base Vertex AI endpoint to use for the request. If
     *        not provided, the default regionalized endpoint
     *        (i.e. us-central1-aiplatform.googleapis.com) will be used.
     * @param {GoogleAuthOptions} - [googleAuthOptions] The Authentication options provided by google-auth-library.
     *        Complete list of authentication options is documented in the GoogleAuthOptions interface:
     *        https://github.com/googleapis/google-auth-library-nodejs/blob/main/src/auth/googleauth.ts
     */
    constructor(project: string, location: string, apiEndpoint?: string | undefined, googleAuthOptions?: GoogleAuthOptions<import("google-auth-library/build/src/auth/googleauth").JSONClient> | undefined);
    /**
     * Get access token from GoogleAuth. Throws GoogleAuthError when fails.
     * @return {Promise<any>} Promise of token
     */
    get token(): Promise<any>;
    /**
     * @param {ModelParams} modelParams - {@link ModelParams} Parameters to specify the generative model.
     * @return {GenerativeModel} Instance of the GenerativeModel class. {@link GenerativeModel}
     */
    getGenerativeModel(modelParams: ModelParams): GenerativeModel;
}
/**
 * Params to initiate a multiturn chat with the model via startChat
 * @property {Content[]} - [history] history of the chat session. {@link Content}
 * @property {SafetySetting[]} - [safety_settings] Array of {@link SafetySetting}
 * @property {GenerationConfig} - [generation_config] {@link GenerationConfig}
 */
export declare interface StartChatParams {
    history?: Content[];
    safety_settings?: SafetySetting[];
    generation_config?: GenerationConfig;
}
/**
 * All params passed to initiate multiturn chat via startChat
 * @property {VertexAI_Preview} - _vertex_instance {@link VertexAI_Preview}
 * @property {GenerativeModel} - _model_instance {@link GenerativeModel}
 */
export declare interface StartChatSessionRequest extends StartChatParams {
    _vertex_instance: VertexAI_Preview;
    _model_instance: GenerativeModel;
}
/**
 * Chat session to make multi-turn send message request.
 * `sendMessage` method makes async call to get response of a chat message.
 * `sendMessageStream` method makes async call to stream response of a chat message.
 */
export declare class ChatSession {
    private project;
    private location;
    private historyInternal;
    private _vertex_instance;
    private _model_instance;
    private _send_stream_promise;
    generation_config?: GenerationConfig;
    safety_settings?: SafetySetting[];
    get history(): Content[];
    /**
     * @constructor
     * @param {StartChatSessionRequest} request - {@link StartChatSessionRequest}
     */
    constructor(request: StartChatSessionRequest);
    /**
     * Make an sync call to send message.
     * @param {string | Array<string | Part>} request - send message request. {@link Part}
     * @return {Promise<GenerateContentResult>} Promise of {@link GenerateContentResult}
     */
    sendMessage(request: string | Array<string | Part>): Promise<GenerateContentResult>;
    appendHistory(streamGenerateContentResultPromise: Promise<StreamGenerateContentResult>, newContent: Content): Promise<void>;
    /**
     * Make an async call to stream send message. Response will be returned in stream.
     * @param {string | Array<string | Part>} request - send message request. {@link Part}
     * @return {Promise<StreamGenerateContentResult>} Promise of {@link StreamGenerateContentResult}
     */
    sendMessageStream(request: string | Array<string | Part>): Promise<StreamGenerateContentResult>;
}
/**
 * Base class for generative models.
 * NOTE: this class should not be instantiated directly. Use
 * `vertexai.preview.getGenerativeModel()` instead.
 */
export declare class GenerativeModel {
    model: string;
    generation_config?: GenerationConfig;
    safety_settings?: SafetySetting[];
    private _vertex_instance;
    private _use_non_stream;
    private publisherModelEndpoint;
    /**
     * @constructor
     * @param {VertexAI_Preview} vertex_instance - {@link VertexAI_Preview}
     * @param {string} model - model name
     * @param {GenerationConfig} generation_config - Optional. {@link
     *     GenerationConfig}
     * @param {SafetySetting[]} safety_settings - Optional. {@link SafetySetting}
     */
    constructor(vertex_instance: VertexAI_Preview, model: string, generation_config?: GenerationConfig, safety_settings?: SafetySetting[]);
    /**
     * Make a async call to generate content.
     * @param request A GenerateContentRequest object with the request contents.
     * @return The GenerateContentResponse object with the response candidates.
     */
    generateContent(request: GenerateContentRequest | string): Promise<GenerateContentResult>;
    /**
     * Make an async stream request to generate content. The response will be returned in stream.
     * @param {GenerateContentRequest} request - {@link GenerateContentRequest}
     * @return {Promise<StreamGenerateContentResult>} Promise of {@link StreamGenerateContentResult}
     */
    generateContentStream(request: GenerateContentRequest | string): Promise<StreamGenerateContentResult>;
    /**
     * Make a async request to count tokens.
     * @param request A CountTokensRequest object with the request contents.
     * @return The CountTokensResponse object with the token count.
     */
    countTokens(request: CountTokensRequest): Promise<CountTokensResponse>;
    /**
     * Instantiate a ChatSession.
     * This method doesn't make any call to remote endpoint.
     * Any call to remote endpoint is implemented in ChatSession class @see ChatSession
     * @param{StartChatParams} [request] - {@link StartChatParams}
     * @return {ChatSession} {@link ChatSession}
     */
    startChat(request?: StartChatParams): ChatSession;
}
